{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc7d9dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Basic Text Manipulation and NLTK \n",
    "\n",
    "\n",
    "The nltk python package provides a lot of useful features when working with language. It provides corpora, tokenizers, parsers, and other useful functions. For Details see: [https://www.nltk.org/](https://www.nltk.org/)\n",
    "\n",
    "This notebook goes through some basics of nltk in combination with string manipulation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f9f47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`nltk` provides useful corpora, we can use as examples in this notebook. You can download data from nltk bei using `nltk.download()`. For this notebook only the `book` package is necessary. It provides the gutenberg corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eae773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9074f45",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084a6bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A corpus in the nltk package provides textual resources or annotations. \n",
    "\n",
    "The nltk function `nltk.corpus.gutenberg.fileids()` returns all the available fileid's of the book corpus we downloaded. These are used to retrieve the texts:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a84e8d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca8f261",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.raw('carroll-alice.txt')\n",
    "text[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d43cc9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It is also possible to load pre-tokenized text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a02c8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.words('carroll-alice.txt')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bd78d2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d024b9d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.sents('carroll-alice.txt')\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b95491",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text manipulation\n",
    "\n",
    "NLTK provides a lot of useful functions for basic text manipulation, like tokenizers or ngram generators. \n",
    "\n",
    "#### ngrams\n",
    "There are functions for ngram generation: `nltk.bigram`, `nltk.trigram` or more general `nltk.ngram`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f18270",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Bigrams:\", list(nltk.bigrams([\"Where\", \"is\", \"my\", \"money\", \"man\", \"?\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7688cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Trigrams:\", list(nltk.trigrams([\"Where\", \"is\", \"my\", \"money\", \"man\", \"?\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b1a01a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The more general version of ngrams can generate higher orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fecbfb6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list(nltk.ngrams([\"Where\", \"is\", \"my\", \"money\", \"man\", \"?\"], n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe32193",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The function works on python lists level. That means actually you can get any ordered subsequence from any list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170d900",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list(nltk.ngrams([[\"first\", \"element\"], [\"second\", \"element\"], [\"third\", \"element\"]], n=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710936f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "or even"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66418fec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "list(nltk.ngrams(\"Where is my money man ?\", n=3))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b871637",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### tokenizers\n",
    "Two other very useful functions to work with text are the tokenizers. \n",
    "Most importantly:\n",
    "`nltk.word_tokenizer` and `nltk.sent_tokenizer` to split a string of text into words or sentences respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff877ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "example = \"This happened long before she met the Queen of Hearts. The \"\\\n",
    "\"rabbit-hole went straight on like a tunnel for some way, \"\\\n",
    "\"and then dipped suddenly down, so suddenly that Alice had not a moment \"\\\n",
    "\" to think about stopping herself before she found herself falling down \"\\\n",
    "\" a very deep well. Alice's heart skipped a beat.\"\n",
    "        \n",
    "print(\"Text: \\n\", example.split(\" \"))\n",
    "print(\"\\n\")\n",
    "print(\"Words: \\n\", nltk.word_tokenize(example))\n",
    "print(\"\\n\")\n",
    "print(\"Sentences: \\n\", nltk.sent_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51f5859",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1: Cleaning texts \n",
    "\n",
    "Typically not all symbols are relevant for processing, although this is highly task specific.\n",
    "Usually unwanted or not needed symbols comprise of:\n",
    " - escaped characters (\\n\\t\\r)\n",
    " - repeated white spaces (\"      \" -> \" \")\n",
    " - Sometimes punctuation\n",
    "\n",
    "Therefore the first step in language processing often is to look at the text and clean the string to match the expectation in a way.\n",
    "\n",
    "\n",
    "For example, let's remove all characters from the string that are not contained in the alphabet or useful punctuation like `\"!?.,; -\"`.\n",
    "\n",
    "Useful helper for this is the `string` module which contains precompiled lists like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ffd85",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "print(\"Punctuation: \", string.punctuation)\n",
    "print(\"Digits: \", string.digits)\n",
    "print(\"letters: \", string.ascii_letters)\n",
    "print(\"letters: \", string.ascii_lowercase)\n",
    "print(\"Punctuation: \", string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ee937e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = nltk.corpus.gutenberg.raw('carroll-alice.txt') # RELOAD RAW TEXT\n",
    "import re  # regular expression operations\n",
    "\n",
    "def clean(s :str) -> str:\n",
    "    valid = string.ascii_letters + \"!?.,; -\"\n",
    "    s = \"\".join([c if c in valid else \" \" for c in s])\n",
    "    s = re.sub(\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "print(\"Before: \\n\", [text[:1000]])\n",
    "clean_text = clean(text)\n",
    "print(\"\\n\\n After:\\n\",clean_text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38272365",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 2: Counting\n",
    "\n",
    "On the lowest linguistic level, there are characters and symbols. These are the most basic units of a language. \n",
    "However, while many languages share their alphabets, statistical use can differ significantly.\n",
    "\n",
    "To establish a statistical view on text, we usually start by counting occurrences.\n",
    "NLTK has a useful class for this:\n",
    "`nltk.FreqDist(text1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29facdd0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "f = nltk.FreqDist(clean_text) # try with a word list as input, too!\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd870d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "f.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a69390",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a30acc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 3 - Word Level \n",
    "\n",
    "The next level are tokens or types. \n",
    "\n",
    "To count the tokens in a text, we first need to split the text into tokens. We use `nltk.tokenize.word_tokenize`\n",
    "to for example calculate the average word length in a text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e58ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def average_word_length(text: str) -> float:\n",
    "    tokens = nltk.tokenize.word_tokenize(text.lower())\n",
    "    lengths = [len(x) for x in tokens] \n",
    "    return sum(lengths)/len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1556f76e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "average_word_length(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d333f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 4 - Sentence level \n",
    "\n",
    "The next level of composition is sentence level. We can use `nltk.tokenize.sent_tokenize` to split strings into sentences. Write a function to calculate the average number of tokens per sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04308b04",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def average_token_per_sentence(text: str) -> float:\n",
    "    sentences =  nltk.tokenize.sent_tokenize(text)\n",
    "    lengths = [len(nltk.tokenize.word_tokenize(sentence)) for sentence in sentences]\n",
    "    return sum(lengths) / len(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e2a5f-d6b2-413c-baa9-d3a2b4f53e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_token_per_sentence(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c51f1c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 5 - Part Of Speech\n",
    "\n",
    "\n",
    "Part-Of-Speech Tagging assignes a grammatical function for each word in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a623367",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tag = nltk.pos_tag(nltk.word_tokenize(text)) # try parameter tagset=\"universal\"\n",
    "tag[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f8837",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The set of tags is taken from the Penntree POS Tags set and can be found here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8884ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame    \n",
    "IFrame(\"https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\", width=800, height=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f6f908-709f-4caa-957a-6926bc54bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"https://universaldependencies.org/u/pos/index.html\", width=800, height=650)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e704c6",
   "metadata": {},
   "source": [
    "## Task 6: String Similarity\n",
    "\n",
    "NLTK provides various functions for similarity measures.\n",
    "NLTK provides an implementation of the edit distance in `nltk.edit_distance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7174f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Mouse, House\", nltk.edit_distance(\"Mouse\", \"House\"))\n",
    "print(\"Alice\", \"Alice's\", nltk.edit_distance(\"Alice\", \"Alice's\"))\n",
    "print(\"Hausbedarfsladenkette, Mausbedarfsladenkette\", nltk.edit_distance(\"Hausbedarfsladenkette\", \"Mausbedarfsladenkette\"))\n",
    "print(\"NLP is a lot of fun!\", \"NLP is a lot of work!\", nltk.edit_distance(\"NLP is a lot of fun!\", \"NLP is a lot of work!\"))\n",
    "print(\"work\", \"workhorse\", nltk.edit_distance(\"work\", \"workhorse\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930965fc",
   "metadata": {},
   "source": [
    "Another similarity measure for strings mentioned in the lecture was the DICE-measure.\n",
    "\n",
    "A good exercise to get familiar with the basics of python/nltk is to implement a function that implements a DICE measure yourself.\n",
    "\n",
    "Try to compare `(\"House\", \"Mouse\")` and `(\"Alice\", \"Alice's\")` using the dice-coefficient for trigrams and edit distance. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43108d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(w1: str, w2: str, n: int) -> float:\n",
    "    n1 = set(nltk.ngrams(w1, n))\n",
    "    n2 = set(nltk.ngrams(w2, n))\n",
    "    dice = 2 * len(n1.intersection(n2)) / (len(n1) + len(n2))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1857cf8-1e8f-49d9-8d16-1a1c0f7d94a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "print(\"Mouse, House\", dice_score(\"Mouse\", \"House\", n))\n",
    "print(\"Aliceiceiceiceice\", \"Aliciceicee's\", dice_score(\"Alice\", \"Alice's\",n))\n",
    "print(\"Hausbedarfsladenkette, Mausbedarfsladenkette\", dice_score(\"Hausbedarfsladenkette\", \"Mausbedarfsladenkette\",n))\n",
    "print(\"NLP is a lot of fun!\", \"NLP is a lot of work!\", dice_score(\"NLP is a lot of fun!\", \"NLP is a lot of work!\", n))\n",
    "print(\"work\", \"workhorse\", dice_score(\"work\", \"workhorse\", 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f81e47-0de4-4ca8-99af-668e20f0da82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
