{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffcc9698",
   "metadata": {},
   "source": [
    "# Generating Synthetic Text\n",
    "\n",
    "In this exercise we try to use character ngrams to generate synthetic text, see \"künstliche Sprache\" (Kupfmüller).\n",
    "\n",
    "The main idea is to establish a ngram statistic of a given corpus. The frequencies of the ngrams is assumed to approximate the probability of a specific ngram to occurr in any given text of that language.\n",
    "\n",
    "We can use this assumption to generate a sequence of characters.\n",
    "\n",
    "More precisely: If we have the ngram statistic and see an \"(n-1)-gram\" $t$, we can restrict the established ngram statistic to only matching ngrams that start with $t$. The probabilites in the resulting list can be renormalized and sampled from. The last character of the sampled ngram is the new character.\n",
    "\n",
    "\n",
    "#### The algorithm is:\n",
    "   1. Establish the $n$-gram probabilities of a corpus (ngram with respective probability). To keep computational effort low introduce a parameter $k$, which restricts the n-grams statistics to the top $k$ most frequent ones. \n",
    "   2. For a given string $s$ predict the next character (see next algorithm)\n",
    "   3. Repeat step two to generate as many next characters as you want\n",
    "   \n",
    "#### Generate the next character for input $s$ by:\n",
    "   1. Take the last $(n-1)$ characters of $s$ as substring $t$\n",
    "   2. Restrict the known ngrams to ngrams that start with $t$\n",
    "   3. Sample from this list of ngrams according to the probabilities\n",
    "   4. Take last character of this ngram and add to initial string\n",
    "   \n",
    "#### Ressources\n",
    "As a basis you can again use the books corpus as a whole.\n",
    "This time, for the creation of synthetic text it is important that the corpus contains spaces and punctuation. Otherwise the resulting text will contain no spaces and punctuation!\n",
    "\n",
    "Also for the sampling process, have a look at `numpy.random.choice` which allows you to put in a list of symbols and a list of corresponding probabilities and returns an element according to them. (The library can be installed with `conda install numpy` or `pip install numpy`)\n",
    "\n",
    "\n",
    "#### Deliberations:\n",
    "A crucial part of this is the sampling process in step 3.\n",
    "What would be the problem with just returning the ngram with the highest probability?\n",
    "\n",
    "What is the influence of the size of $n$?\n",
    "\n",
    "What is the influence of $k$?\n",
    "\n",
    "What are some restrictions of this approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc888786",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb40d423",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_text = nltk.corpus.gutenberg.raw(nltk.corpus.gutenberg.fileids())#[:200000]\n",
    "english_text[:200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f494e-f9c0-4af9-baa5-5ce0d5aeea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageGenerator:\n",
    "    def __init__(self, text, n=3, topk=10000):\n",
    "        ngrams = nltk.FreqDist(nltk.ngrams(text.lower(), n)).most_common(topk) \n",
    "        \n",
    "        self.n = n\n",
    "        self.grams = [\"\".join(x[0]) for x in ngrams]\n",
    "        self.counts = np.array([x[1] for x in ngrams]) # saving as numpy array\n",
    "        self.probablities = self.counts / self.counts.sum()\n",
    "    \n",
    "    \n",
    "    def generate(self, text):        \n",
    "        # Get last n-1 characters of the input\n",
    "        prefix = text[-(self.n-1):]\n",
    "        \n",
    "        # Find all the ngrams starting with the prefix\n",
    "        indices = [i for i, gram in enumerate(self.grams) if gram.startswith(prefix)] \n",
    "        \n",
    "        if len(indices) == 0:\n",
    "            # If there are no ngrams starting with the ngrams\n",
    "            character = np.random.choice(list(string.ascii_lowercase))\n",
    "            text = text + character\n",
    "        else:\n",
    "            probs = self.probablities[indices]\n",
    "            probs = probs / probs.sum() # Renormalize!\n",
    "\n",
    "            # Sample\n",
    "            selection = np.random.choice(indices, p=probs)        \n",
    "            text = text + self.grams[selection][-1]\n",
    "        return text\n",
    "\n",
    "    def generate_n(self, text, n = 100):\n",
    "        for _ in range(n):\n",
    "            text = self.generate(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06202f9d-56eb-4ad3-a568-11cdcf8db43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langen = LanguageGenerator(english_text, n=4, topk=100000) # try different parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fdba07-dd23-443c-918c-6321d89fbfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "langen.generate_n(\"Hello my namy is Alice\", n=500) # try different start strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c96313d-1f35-4279-87d2-6548e4da863f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
