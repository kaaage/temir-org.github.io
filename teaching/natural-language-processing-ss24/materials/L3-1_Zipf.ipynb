{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90749bee",
   "metadata": {},
   "source": [
    "# Zipf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24be01d8",
   "metadata": {},
   "source": [
    "# A1.  Zipf’sches Gesetz - Understanding\n",
    "\n",
    "\n",
    "Rate the following statement as true or false and briefly justify your decision! \n",
    "\n",
    "\n",
    " 1. If you plot the ranks and frequencies of words from a corpus in a coordinate system, you get a straight line according to Zipf's law.\n",
    "\n",
    " 2. From Zipf's law follows that the number of different word forms (types) in a text is proportional to its length.  \n",
    "\n",
    " 3.  If one plots the curves to Zipf's law for several corpora of a language in a double logarithmic coordinate system, one obtains approximately parallel curves.\n",
    "\n",
    " 4. The constant c is different for different languages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258c5780",
   "metadata": {},
   "source": [
    "# A2. The long tail of the distribution\n",
    "\n",
    "From the lecture: It holds $w_n$ - the number of types that occurr $n$ times in a given corpus - fullfills the equation $$ w_n = r_n – r_{n+1} $$\n",
    "    \n",
    " \n",
    "How many words will likely occur only once in any given text? Deduce a formula."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae01d3",
   "metadata": {},
   "source": [
    "# A3. Application of Zipf's Law\n",
    "Given the following data from an english corpus with a total number of 71.370 words (tokens):\n",
    "\n",
    "|  Word  | Frequency | Rank |\n",
    "|-------|-----------|------|\n",
    "| he    | 877       | 10   |\n",
    "| but   | 410       | 20   |\n",
    "| comes | 16        | 500  |\n",
    "| applausive | 1    | 8000 |\n",
    "\n",
    "\n",
    "\n",
    "(a) Estimate Zipf's constant from this data.\n",
    "\n",
    "(b) From that estimation derive:\n",
    "    \n",
    "    - What will be the number of different word forms (types)? \n",
    "    - How many of them will appear only once in the text? \n",
    "    - Related to the total number of tokens: How high will be the share of word forms that occur only once in the text?\n",
    "    \n",
    " (c) After estimation, assume that `applausive` is the word with the lowest rank and calulate the Zipf constant mathematically by using the Harmonic Series.\n",
    " \n",
    " (d) What is the difference of the two methods to obtain $c$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b111c7d",
   "metadata": {},
   "source": [
    "# A4. - Further Application of Zipf’s Law\n",
    "From the lecture:$r(n_w=x)$ gives the largest rank of all word forms that occur $x$ times in the corpus.\n",
    "The number of types that probably occur exactly $n$ times in a given corpus $w_n$ fulfills the equation $$ w_n = r_{n} – r_{n+1} $$\n",
    "\n",
    "a) Deduce a formula to generalize this result to calculate the number of words that probably occur $n$ to $m$ times in a corpus.\n",
    "\n",
    "Given a text corpus of German with 1 million sentences and 16 015 429 tokens. (Assume c=0.08)\n",
    "\n",
    "(b) How large is the vocabulary according to Zipf's law?\n",
    "    \n",
    "(c) How many words occur 100 times or more in this text according to Zipf's law?\n",
    "\n",
    "(d) According to Zipf's law, how many words occur exactly 100 times in this text?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339ecacc",
   "metadata": {},
   "source": [
    "# Programming\n",
    "\n",
    "We can use some of the corpora to empirically verify the Zipf assumptions. \n",
    "\n",
    "Use the complete books corpus as English corpus.\n",
    "\n",
    "As German Corpus we will upload a corpus of news articles from Tagesschau.\n",
    "\n",
    "If you are interested in other resources or other languages see [here](https://wortschatz.uni-leipzig.de/en/download/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97669b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbcc78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_german_text(path):\n",
    "    text = \"\"\n",
    "    for f in pathlib.Path(path).glob(\"*.txt\"):\n",
    "        with open(f, \"r\") as openf:\n",
    "            text += nltk.word_tokenize(openf.read(), language=\"german\")\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b221c9f",
   "metadata": {},
   "source": [
    "## P1 - The Zipf Constant\n",
    "\n",
    "Write two functions that each return the zipf constant.\n",
    "\n",
    "    a) Try to estimate the Zipf constant by using empirical frequencies and ranks from the data. (Restrict to rank 10 to 10000.\n",
    "    b) Calculate the Zipf constant by using the Harmonic Series.\n",
    "\n",
    "What happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfd2ca7",
   "metadata": {},
   "source": [
    "## P2 - Words Occuring Once\n",
    "\n",
    "We predict that have of the vocabularies in real corpora only occur once. Write a function that confirms the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d688fd9",
   "metadata": {},
   "source": [
    "# P3  - Text Coverage\n",
    "\n",
    "The Zipf power law follows similar patterns to the Pareto law (see [here](https://en.wikipedia.org/wiki/Pareto_principle#:~:text=The%20Pareto%20principle%20states%20that,the%20principle%20of%20factor%20sparsity.)).\n",
    "\n",
    "Not only does a large percentage of words only occur once, also very few words already cover high percentages of any written text.\n",
    "\n",
    "Calculate the text coverage in dependence of rank.\n",
    "\n",
    "Plot the results.\n",
    "\n",
    "What percentage of all words in the vocabulary are needed to cover 80 % of the text corpus ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976fc17",
   "metadata": {},
   "source": [
    "# P3 - Ngrams\n",
    "\n",
    "\n",
    "The Zipf law is a special case of a power law. These hold for many other natural occurring things aswell.\n",
    "\n",
    "Verify a similar relation for character ngrams. \n",
    "(Not a mathematical proof. Convince yourself by plotting or looking at the rank/frequency product.)\n",
    "\n",
    "(Reuse above code if possible!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e2f19",
   "metadata": {},
   "source": [
    "## How many ngrams cover 80% of the text ? \n",
    "\n",
    "How many of the top frequent ngrams would you need to cover 80% of the text.\n",
    "\n",
    "How much do these top ngrams overlap for German and English?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13f5ee",
   "metadata": {},
   "source": [
    "## You can use this information in the Application Task in Notebook `Language Detection`. ( You can also go for 90% or 95% text coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493cb12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
