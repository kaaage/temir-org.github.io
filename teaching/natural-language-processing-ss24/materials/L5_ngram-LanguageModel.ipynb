{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2561bd4-363c-429d-8222-eee54f25ee5d",
   "metadata": {},
   "source": [
    "#  N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1161189",
   "metadata": {},
   "source": [
    "## A1 - Linear Interpolation\n",
    "\n",
    "A Corpus for the German language consists of the two sentences:\n",
    "\n",
    "            (1) Johann gibt Marie das Manuskript.\n",
    "            (2) Peter sieht, dass Johann Marie das Buch gibt.\n",
    "\n",
    "Calculate the probabilities of the sentences *\"Johann gibt Marie das Buch.\"* and *\"Peter sieht das Buch.\"*\n",
    "\n",
    "**(a)** for a \"classic\" **trigram** model trained on sentences (1)-(2). For this excercise, we will ***ignore punctuation*** and only focus on actual words. \n",
    "\n",
    "**(b)** like in (a), but using simple linear interpolation for the trigrams, with the following weighting factors when smoothing:\n",
    "\n",
    "$\\lambda_3 = 0.80$ (Trigrams)<br>\n",
    "$\\lambda_2 = 0.15$ (Bigrams)<br>\n",
    "$\\lambda_1 = 0.05$ (Unigrams)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83065f9",
   "metadata": {},
   "source": [
    "## A2 - Language Model with Padding\n",
    "\n",
    "For plain language models there is the problem of the beginning of a sentence:\n",
    "The probability that a unigram occurs should not be the same as the probability that it occurs in the beginning of the sentence. To cope with this we can add special padding symbols around the sentence.\n",
    "Now $P((\\text{<s>}, w_i))$ marks the probability that a sentences starts with $ w_i$.\n",
    "\n",
    "For a **bigram** language model we can now replace the first factor in the probability formula by the padded words, from:\n",
    "\n",
    "$P((w_1,w_2,...w_n)) = P(w_1) \\cdot P(w_2|w_1) \\cdot P(w_3|w_2)\\cdot\\dots\\cdot P(w_n|w_{n-1})$\n",
    "\n",
    "to:\n",
    "\n",
    "$P((w_1,w_2,...w_n)) = P(w_1|\\text{<s>}) \\cdot P(w_2|w_1) \\cdot P(w_3|w_2)\\cdot\\dots\\cdot P(w_n|w_{n-1}) \\cdot P(\\text{</s>}|w_n)$\n",
    "    \n",
    "    \n",
    "This better reflects the probability of how likely $w_1$ will occur at the start of a sentence.\n",
    "Same argument holds for words at the end of sentence and `</s>`.\n",
    "\n",
    "    \n",
    "\n",
    "Consider the following toy example (similar to the one from Jurafsky & Martin, 2021):\n",
    "\n",
    "**Training data:**\n",
    "\n",
    "`<s> I am Sam </s>`<br>\n",
    "`<s> Sam I am </s>`<br>\n",
    "`<s> Sam I like </s>`<br>\n",
    "`<s> Sam I do like </s>`<br>\n",
    "`<s> do I like Sam </s>`<br>\n",
    "\n",
    "Assume that we use a bigram language model (without smoothing or interpolation) based on the above training data.\n",
    "\n",
    "1. What is the most probable next word predicted by the model for the following word sequences?<br>\n",
    "    (1) `<s> Sam ...`<br>\n",
    "    (2) `<s> Sam I do ...`<br>\n",
    "    (3) `<s> Sam I am Sam ...`<br>\n",
    "    (4) `<s> do I like ...`<br>\n",
    "\n",
    "2. Which of the following sentences gets assigned the highest probability with this model?\n",
    "\n",
    "    (5) `<s> Sam I do I like </s>`<br>\n",
    "    (6) `<s> Sam I am </s>`<br>\n",
    "    (7) `<s> I do like Sam I am </s>`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3124b4",
   "metadata": {},
   "source": [
    "## A3 - Perplexity\n",
    "Consider again the same training data as in **A2** and the same bigram model. Compute the perplexity of\n",
    "\n",
    "`<s> I do like Sam`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa5194",
   "metadata": {},
   "source": [
    "## A4 - Laplace Smoothing\n",
    "Take again the same training data as in **A2**. This time, we use a bigram LM with **Laplace smoothing**.\n",
    "\n",
    "1. Give the following bigram probabilities estimated by this model:\n",
    "\n",
    "    `P(do|<s>), P(do|Sam), P(Sam|<s>), P(Sam|do), P(I|Sam), P(I|do), P(like|I)`\n",
    "    \n",
    "2. Calculate the probabilities of the following sequences according to this model:<br>\n",
    "    (8) `<s> do Sam I like`<br>\n",
    "    (9) `<s> Sam do I like`<br>\n",
    "    \n",
    "    Which of the two sequences is more probable according to our LM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3577944",
   "metadata": {},
   "source": [
    "#### Reference:\n",
    "*D. Jurafsky, J. H. Martin: Speech and Language Processing (3rd ed. Draft), https://web.stanford.edu/~jurafsky/slp3/, 2021*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
